---
title: "Replication: Measuring Political Sophistication through Textual Complexity"
author: "Zhiqiang Ji"
date: "Feb 21, 2024"
title-slide-attributes:
  data-background-image: "img/title_background.jpeg"
  data-background-opacity: "0.3"
format: 
  revealjs:
    theme: serif
    mermaid: {}
    transition: slide
    incremental: true
---

# Introduction

## The original paper
Benoit, K., Munger, K. and Spirling, A. (2019), Measuring and Explaining Political Sophistication through Textual Complexity. American Journal of Political Science, 63: 491-508. <https://doi.org/10.1111/ajps.12423>

  - Research Question: Political scientists lack domain-specific measures for the purpose of measuring the sophistication of political communication. 
  
# Methods

## Data
- The text data used in the study primarily consists of paragraphs from the State of the Union (SOTU) addresses, parsed and prepared for analysis. 

## Develop statistically valid measures of textual complexity

1. **Obtain human judgments**
2. **Estimate latent easiness**: Apply an *unstructured Bradley-Terry model* 
3. **Identify the best predictors**
4. **Fit structured Bradley-Terry Model**: Fit a *structured Bradley-Terry model* 
5. **Prediction**: Use this model to predict the easiness of new texts

## Crowdsourcing: Details

- Obtain human judgments on the relative easiness of political text snippets through crowdsourcing.
- Snippets were two-sentence segments from post-1950 State of the Union addresses
- Removed non-sentence text and disqualified snippets based on specific criteria, such as FRE score.
- Snippets were grouped into bands based on word count (345â€“60, 360â€“75, 375â€“90 words)
- A total of 2000+ snippet pairs were randomly chosen for crowdsourced comparison.
- "Gold pairs"(~15% of the tasks) were utilized as a quality control mechanism. 

## Develop the model

:::: {.columns}

::: {.column width="60%"}
- Fit an *unstructured Bradley-Terry model* to the human judgments to estimate latent easiness.
- Add possible predictors/covariates to the model (22 predictors to test)
:::


::: {.column width="40%"}
![](img/22.png){.fragment width="250" height="500"}
:::
::::

## Develop the model (cont'd)

- **Identify the best predictors**

![](img/rf.png){.fragment width="750" height="550"}

## Develop the model (cont'd)

- Using the Selected Predictors to Fit a *Structured Bradley-Terry Model* to get a statistical model of textual complexity.
- Employing nonparametric *bootstrapping* for uncertainty in predictions.


# Results

## Model Performance

- The new model achieved a proportion correctly predicted (PCP) score of 0.585, which adjusted to the mean best possible performance is 74% (0.741).
 
- Flexibility of the model
- Interpretability
- Uncertainty in predictions
  
---

![](img/perf.png){.fragment width="750" height="550"}

## Example 1

- SOTU snippets in comparison with fifth-grade reading level (which is scaled to 100)
- Obama's snippet is a little bit easier for a fifth-grader ðŸ˜‚

![](img/101.png){.fragment width="550" height="200"}

## Example 2

- The readability of State of the Union addresses slight increase in simplicity over time.
- The baseline above is the fifth-grade reading level

![](img/hard.png){.fragment width="850" height="550"}

## Differences

- Did not replicate the crowdsourcing part of the study.
- Possible typo in Table 2
- Trivial differences such as the results of RF.

---

The PCP scores for "FRE Reweight" and "Basic RF" in the original code note is reversed in the paper ðŸ˜•

:::: {.columns}

::: {.column width="40%"}
![](img/typo1.png){.fragment width="250" height="400"}
:::


::: {.column width="60%"}
![](img/typo2.png){.fragment width="450" height="180"}
:::
::::

## Autopsy of the replication

- Compatibility Issues
- Discrepancies Between Theory and Practice

::: {.notes}
- Faced compatibility challenges with specific Python packages and libraries due to CPU architecture differences (x86_64 vs. arm64), leading to error messages and difficulties in executing code as intended.
- Encountered outdated packages (e.g., "apsrtable") that are no longer available or supported, necessitating workarounds or alternatives to achieve similar functionality.
- Noticed gaps between the theoretical framework presented in the paper and its practical implementation in the code.
- Required additional technical decisions not specified in the paper, like whether to apply bias reduction in the Bradley-Terry (BT) model or choosing between Variable Selection Using Random Forests (VSURF) versus standard RF, which had significant impacts on the analysis outcomes.
:::

## Extension

- Integration of Advanced Language Models like ChatGPT
- Enhanced the model
- Expanding the Scope of Text Sources

