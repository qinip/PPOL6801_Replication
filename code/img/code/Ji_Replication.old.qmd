---
title: "Replication: Benoit et al.(2019) Measureing and Explaining Political Sophistication through Textual Complexity"
author: "Zhiqiang Ji"
format: 
  html:
    code-fold: false
    toc: true
    toc-depth: 3
    toc-float:
      collapsed: false
      smooth-scroll: true
    self-contained: true
execute:
  warning: false
  error: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(reticulate)
use_condaenv("ppol6801", conda = "C:/Users/j_i/anaconda3/condabin/conda.bat", required = TRUE)

# install.packages("BradleyTerry2")
# devtools::install_github("quanteda/quanteda")  
# devtools::install_github("quanteda/quanteda.corpora") 
# install.packages(c("spacyr", "randomForest", "apsrtable"))
# devtools::install_github("quanteda/spacyr", build_vignettes = FALSE)
library("spacyr")
spacy_install()
spacy_initialize()
# devtools::install_github("kbenoit/sophistication")

library("sophistication")
library("tidyverse")
library("randomForest")
library("quanteda")
library("quanteda.corpora")
library("quanteda.textmodels")
```

## 03 generate sentence covariates
```{r}
# read in the last two jobs
allsentences <-
    rbind(read.csv("data/CF_output_f999866.csv", stringsAsFactors = FALSE),
          read.csv("data/CF_output_f952737.csv", stringsAsFactors = FALSE))
# 27807 obs. of  25 variables

# create chameleons format data
# note: this also requires spacyr to be installed
job999866covars_chameleons <-
    bt_input_make(allsentences, covars = TRUE,
                  readability_measure = c("Flesch",
                                          "Dale.Chall",
                                          "FOG",
                                          "SMOG",
                                          "Spache",
                                          "Coleman.Liau"),
                  covars_baseline = TRUE, covars_pos = TRUE, normalize = TRUE)

save(job999866covars_chameleons, file = "data/my_job999866covars_chameleons.rda")

# job999866covars_chameleons_normalized <-
#     bt_input_make(allsentences, covars = TRUE, readability_measure = "Flesch",
#                   covars_baseline = TRUE, covars_pos = TRUE, normalize = TRUE)
#
# save(job999866covars_chameleons_normalized, file = "R_intermediate/job999866covars_chameleons_normalized.rda")



##
## the same data, as a data.frame
##

require(sophistication)

## get sentences

allsentences <-
    rbind(read.csv("data/CF_output_f999866.csv", stringsAsFactors = FALSE),
          read.csv("data/CF_output_f952737.csv", stringsAsFactors = FALSE))
# select just the text and their IDs
allsentences <- allsentences[, c("snippetid1", "text1", "snippetid2", "text2")]
# wrap the sentences
allsentences <- data.frame(snippetid = c(allsentences[, "snippetid1"],
                                         allsentences[, "snippetid2"]),
                           text = c(allsentences[, "text1"],
                                    allsentences[, "text2"]),
                           stringsAsFactors = FALSE)
# just keep the unique ones
allsentences <- allsentences[!duplicated(allsentences$snippetid), ]
nrow(allsentences) # 3322 rows

# create the basic covariates
allsentences_covars <- cbind(
    allsentences,
    covars_make(allsentences$text, readability_measure = "Flesch"),
    covars_make_baselines(allsentences$text)
)

txt <- allsentences$text
names(txt) <- allsentences$snippetid

# add the POS covariates
allsentences_pos <- covars_make_pos(txt)

job999866covars <-
    merge(allsentences_covars, allsentences_pos, by.x = "snippetid", by.y = "doc_id")
save(job999866covars, file = "data/my_job999866covars.rda")
```

## 04 Make unstructured brTandF abilities
```{r}
#6/20/17
#code creates standard objects -- either br=T or br=F to get unstructured abilities
#these can then be 'regressed' (via RF) on variables.  Can look at e.g. varImpPlot 
# See also 'notes' which covers the stuff below.

#6/19/17
# VSURF appears to be struggling with pr_ POS variables -- 
# use standard randomforest instead.

# 6/15/17
#run the unstructured model w and wout br=T
# --> presumably shd give similar results
#Note that we know have POS variables in terms of *rates*

rm(list=ls())

require(sophistication)
require(BradleyTerry2)

load("data/my_job999866covars_chameleons.rda")
dat <- job999866covars_chameleons

##############################################
######################## bias reduction ######
##############################################

# fit unstructured model (br=T)
BT_unstruc_brT <-
    BTm(player1 = easier, player2 = harder, br = TRUE, id = "ID", data = dat)
save(BT_unstruc_brT, file = "data/my_BT_unstructured_brT_abilities.rda")
# save(BT_unstruc_brT, file = paste0(getOption("ROOT_DROPBOX"), "data_AJPS/BT_unstructured_brT_abilities.rda"))


#################################################
######################## no bias reduction ######
#################################################

# fit unstructured model (br=F)
BT_unstruc_brF <- 
    BTm(player1 = easier, player2 = harder, br = FALSE, id = "ID", data = dat)
save(BT_unstruc_brF, file ="data/my_BT_unstructured_brF_abilities.rda")
# save(BT_unstruc_brF, file = paste0(getOption("ROOT_DROPBOX"), "data_AJPS/BT_unstructured_brF_abilities.rda"))
```

## 05 RandomForest variable selection
```{r}
# 7/3/17
# code grabs saved unstructured objects (fitted either via br=T or br=F) and fits RF to them.

# 6/20/17
# code creates standard objects -- either br=T or br=F to get unstructured abilities
# these can then be 'regressed' (via RF) on variables.  Can look at e.g. varImpPlot 
# See also 'notes' which covers the stuff below.

# 6/19/17
# VSURF appears to be struggling with pr_ POS variables -- 
# use standard randomforest instead.

# 6/15/17
# run the unstructured model w and wout br=T
# --> presumably shd give similar results
# Note that we know have POS variables in terms of *rates*

rm(list=ls())

start.time <- Sys.time()
set.seed(42)

library("quanteda")
library("sophistication")
library("BradleyTerry2")

load("data/my_job999866covars_chameleons.rda")
dat <- job999866covars_chameleons
## 2469 docs, 19430 comparisons


##############################################
######################## bias reduction ######
##############################################

# grab the saved objects
# load(paste0(getOption("ROOT_DROPBOX"), "data_AJPS/BT_unstructured_brT_abilities.rda"))
load("data/BT_unstructured_brT_abilities.rda")
BT1 <- BT_unstruc_brT

# locate the relevant predictors in the predictors part of the data
y <- BTabilities(BT1)[, "ability"]
yy <- y[!is.na(y)] #remove NAs
m <- match(names(yy), rownames(dat$predictors))


# collect the possible terms -- note that we remove Flesch (because it's aliased by the other variables)
terms <- c("W3Sy", "W2Sy", "W_1Sy", "W6C", "W7C", "W_wl.Dale.Chall", "Wlt3Sy", 
           "meanSentenceLength", "meanWordSyllables", "meanWordChars", 
           "meanSentenceChars", "meanSentenceSyllables", "brown_mean", "brown_min", 
           "google_mean_2000", "google_min_2000", "pr_noun", "pr_verb", "pr_adjective", 
           "pr_adverb", "pr_clause", "pr_sentence")


X <- dat$predictors[m, terms]

# use randomForest instead of VSURF
library("randomForest")
mod <- randomForest(X, y = yy, ntree = 1000)

mod_bias_reduced<-mod
save(x = mod_bias_reduced, file = "data/my_rf_model_bias_reduced.rda")

# 获取模型的重要性度量
importance_results_brT <- importance(mod_bias_reduced)

inc_node_purity <- importance_results_brT[, "IncNodePurity"]

importance_df_brT <- data.frame(IncNodePurity = inc_node_purity)


# 按IncNodePurity降序排列
importance_df_sorted_brT <- arrange(importance_df_brT, desc(IncNodePurity))
importance_df_sorted_brT

#################################################
######################## no bias reduction ######
#################################################

# grab saved objects
# load(paste0(getOption("ROOT_DROPBOX"), "data_AJPS/BT_unstructured_brF_abilities.rda"))
load("data/BT_unstructured_brF_abilities.rda")
BT2 <-  BT_unstruc_brF

# locate the relevant predictors in the predictors part of the data
y2 <- BTabilities(BT2)[, "ability"]
yy2 <- y2[!is.na(y2)] #remove NAs
mm <- match(names(yy2), rownames(dat$predictors))


X2 <- dat$predictors[mm, terms]

# use randomForest instead of VSURF
mod2 <- randomForest(X2, y = yy2, ntree = 1000)

mod_non_bias_reduced<-mod2
save(x = mod_non_bias_reduced, file = "data/my_rf_model_non_bias_reduced.rda")

importance_results_brF <- importance(mod_non_bias_reduced)

inc_node_purity_F <- importance_results_brF[, "IncNodePurity"]

importance_df_brF <- data.frame(IncNodePurity = inc_node_purity_F)


# 按IncNodePurity降序排列
importance_df_sorted_brF <- arrange(importance_df_brF, desc(IncNodePurity))
importance_df_sorted_brF

##### MOVED to 10_Generate_Figures_1-5.R
dev.new()
par(mfrow=c(2,1))
varImpPlot(mod, main = "Bias Reduced", pch = 16)
varImpPlot(mod2, main = "Not Bias Reduced", pch = 16)

pdf(file = "figures/RF_vimp_plots_4.pdf", width = 11, height = 9)
par(mfrow=c(2,1))
varImpPlot(mod, main = "Bias Reduced", pch = 16)
varImpPlot(mod2, main = "Not Bias Reduced", pch = 16)
dev.off()

# Stop the clock
Sys.time() - start.time

# dev.off()
```

## 06 Additional covariates for the requested texts
```{r}
### make additional covariates for the requested texts

library("sophistication")

library("spacyr")
spacy_initialize()

# SOTU addresses
data(data_corpus_sotu, package = "quanteda.corpora")

x1 <- covars_make(data_corpus_sotu)
x2 <- covars_make_pos(data_corpus_sotu)
x3 <- covars_make_baselines(data_corpus_sotu, 
                            baseline_year = lubridate::year(docvars(data_corpus_sotu, "Date")))

sotu_covars <- cbind(x1, x2, x3)
save(sotu_covars, file = "data/my_sotu_covars.rda")
```

## 07 Best Models Results (Creating Table_2)
```{r}
# 2/19/18 - minor clean up to code.
# note that each of these models takes ~60 seconds to fit.  
# Thus, bootstrapping the pcp is very expensive.

# July 3, 2017
# run the 'optimal models'


rm(list=ls())

## Fit structured BT models ============

library("BradleyTerry2")
load("data/my_job999866covars_chameleons.rda")

# baseline Flesch model
BT_basic_Flesch <- BTm(player1 = easier, player2 = harder, 
                       formula = ~ Flesch[ID], id = "ID", 
                       data = job999866covars_chameleons)


# optimal Flesch model
BT_optimal_Flesch <- BTm(player1 = easier, player2 = harder, 
                         formula = ~ meanSentenceLength[ID] + meanWordSyllables[ID], 
                         id = "ID", data = job999866covars_chameleons)

# basic RF model
BT_basic_RF <- BTm(player1 = easier, player2 = harder, 
                   formula = ~ google_min_2000[ID] + meanSentenceChars[ID] + pr_noun[ID], 
                   id ="ID", data = job999866covars_chameleons)

# best model
BT_best <- BTm(player1 = easier, player2 = harder, 
               formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_noun[ID] + meanWordChars[ID], 
               id = "ID", data = job999866covars_chameleons)

# others we tried
################################### To-Do ##################################
# BT_best_adj <- BTm(player1 = easier, player2 = harder, 
#                formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_noun[ID] + pr_adjective[ID] + meanWordChars[ID], 
#                id = "ID", data = job999866covars_chameleons)
# 
# BT_best_adj_verb <- BTm(player1 = easier, player2 = harder, 
#                         formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_adjective[ID] + pr_verb[ID] + meanWordChars[ID], 
#                         id = "ID", data = job999866covars_chameleons)
# 
# BT_best_noun_adj_verb <- BTm(player1 = easier, player2 = harder, 
#                              formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_noun[ID] + pr_adjective[ID] + pr_verb[ID] + meanWordChars[ID], 
#                              id = "ID", data = job999866covars_chameleons)


# # model dropping pr_noun
# BT_no_noun <- BTm(player1 = easier, player2 = harder, 
#                   formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] +  meanWordChars[ID], 
#                   id = "ID", data = job999866covars_chameleons)
# 
# # model dropping pr_noun adding pr_verb
# BT_verb_no_noun <- BTm(player1 = easier, player2 = harder, 
#                        formula = ~google_min_2000[ID] +  meanSentenceChars[ID] + pr_verb[ID] + meanWordChars[ID], 
#                        id = "ID", data = job999866covars_chameleons)
# 
# BT_adj_no_noun <- BTm(player1 = easier, player2 = harder, 
#                        formula = ~google_min_2000[ID] +  meanSentenceChars[ID] + pr_verb[ID] + pr_adjective[ID] + meanWordChars[ID], 
#                        id = "ID", data = job999866covars_chameleons)
# 
# # model dropping pr_noun adding pr_adjective
# BT_adj_no_noun <- BTm(player1 = easier, player2 = harder, 
#                       formula = ~google_min_2000[ID] +  
#                         meanSentenceChars[ID] + pr_adjective[ID] + meanWordChars[ID], 
#                           id = "ID", data = job999866covars_chameleons)
##############################################################################################

# save the results
model_results <- list(BT_basic_Flesch = BT_basic_Flesch, 
                      BT_basic_RF = BT_basic_RF, 
                      BT_optimal_Flesch = BT_optimal_Flesch, 
                      BT_best = BT_best)
                      # BT_no_noun = BT_no_noun,
                      # BT_adj_no_noun = BT_adj_no_noun,
                      # BT_verb_no_noun = BT_verb_no_noun,
                      # BT_best_adj = BT_best_adj,
                      # BT_best_adj_verb = BT_best_adj_verb,
                      # BT_best_noun_adj_verb = BT_best_noun_adj_verb)
save(model_results, file = "data/my_Best_Model_Results_list.rda")

## NOTE: this is also the object data_BTm_bms in the sophistication R package
save(BT_best, file = "data/my_BT_best.rda")

##  for sophistication package only
# data_BTm_bms <- model_results[["BT_best"]]
# devtools::use_data(data_BTm_bms, overwrite = TRUE)


## OUTPUT FOR TABLE 2 ================

# function for fit (percent corr predicted)
prop.correct <- function(x = BTFRE) { 
    sum(predict(x, type = "response") > .5) / length(predict(x, type = "response"))
}

library("apsrtable")
with(model_results, apsrtable(BT_basic_Flesch, BT_optimal_Flesch, BT_basic_RF, BT_best))

# order the models in descending order of PCP
# model_results <- model_results[names(sort(sapply(model_results, prop.correct), decreasing = TRUE))]

# output models in terms of PCP
table2 <- paste("\nBottom row of TABLE 2\n -----------------------------------------\n",
                sprintf("%-20s ", "Model"), "     PCP      AIC\n",
                "========================  =====  ========\n") 
for (m in seq_along(model_results)) {
    table2 <- paste(table2, 
                    sprintf("%-25s", names(model_results)[m]),
                    sprintf("%2.3f", prop.correct(model_results[[m]]) / .79), 
                    sprintf(" %5.2f", model_results[[m]][["aic"]]), 
                    "\n")
}
table2 <- paste0(table2, " -----------------------------------------\n\n")
cat(table2)


# Bottom row of TABLE 2
#
# Model                      PCP      AIC
# BT_basic_Flesch           0.719  26267.79 
# BT_basic_RF               0.737  25915.01 
# BT_optimal_Flesch         0.738  25910.29 
# BT_best                   0.741  25740.25 



## Bootstrap CIs ===============

# we want to bootstrap the results of a BT model
# to do that, we can use the internal subset= argument
# Except that, in each case, the subset is a sample of all the rows

library("BradleyTerry2")
load("data/my_job999866covars_chameleons.rda")
load("data/my_Best_Model_Results_list.rda")

# function for fit (percent corr predicted)
prop.correct <- function(x = BTFRE) { 
    sum(predict(x, type = "response") > .5) / length(predict(x, type = "response"))
}

# Basic function to do a subset bootstrap
# It returns an accuracy estimate adjusted as it should be
boot.one.time <- function(d = job999866covars_chameleons, refmodel) {
    samp <<- sample(1:nrow(d$easier), nrow(d$easier), replace = TRUE)
    model.call <<- as.formula(refmodel)
    BT_resamp <<- BTm(player1 = easier, player2 = harder, formula = model.call, 
                      id = "ID", data = job999866covars_chameleons, subset = samp)
    adj.acc <<- prop.correct(BT_resamp) / 0.79
    adj.acc
}

attach(model_results)
n <- 500 # number of samples

# baseline Flesch model bootstrap
# so let's fit this to the BT_basic_Flesch model, 2 times
bs.draws_basic <- replicate(n, boot.one.time(d=job999866covars_chameleons, refmodel = BT_basic_Flesch))

# basic RF model
bs.draws_basicRF <- replicate(n, boot.one.time(d=job999866covars_chameleons, refmodel = BT_basic_RF))

# optimal Flesch model
bs.draws_opt <- replicate(n, boot.one.time(d=job999866covars_chameleons, refmodel = BT_optimal_Flesch))

# best model
bs.draws_best <- replicate(n, boot.one.time(d=job999866covars_chameleons, refmodel = BT_best))

BS_results <- data.frame(bs.draws_basic, bs.draws_basicRF, bs.draws_opt, bs.draws_best)
detach(model_results)
save(BS_results, file = "data/bootstrap_results_AJPSR2.rda")

lapply(BS_results, function(y) round(quantile(y, c(0.025, .975)), 3))
# $bs.draws_basic
#  2.5% 97.5% 
# 0.710 0.727 
# 
# $bs.draws_basicRF
#  2.5% 97.5% 
# 0.728 0.747 
#
# $bs.draws_opt
#  2.5% 97.5% 
# 0.729 0.748 
# 
# $bs.draws_best
#  2.5% 97.5% 
# 0.733 0.751 

lapply(BS_results, function(y) round(mean(y), 3))
```

## 08 Generate Table_3
```{r}
# Table 3 in the paper

library("sophistication")

txt_clinton <- "If we do these things-end social promotion; turn around failing schools; build modern ones; support qualified teachers; promote innovation, competition and discipline-then we will begin to meet our generation's historic responsibility to create 21st century schools.  Now, we also have to do more to support the millions of parents who give their all every day at home and at work."

txt_bush <- "And the victory of freedom in Iraq will strengthen a new ally in the war on  terror, inspire democratic reformers from Damascus to Tehran, bring more hope  and progress to a troubled region, and thereby lift a terrible threat from the  lives of our children and grandchildren.  We will succeed because the Iraqi  people value their own liberty---as they showed the world last Sunday."

txt_obama <- "Some schools redesign courses to help students finish more quickly.  Some use better technology.  The point is, it’s possible.  So let me put colleges and universities on notice:  If you can’t stop tuition from going up, the funding you get from taxpayers will go down.Higher education can’t be a luxury -– it is an economic imperative that every family in America should be able to afford."

txt_trump <- "This is a moral issue.  The lawless state of our southern border is a threat to the safety, security, and financial wellbeing of all America.  We have a moral duty to create an immigration system that protects the lives and jobs of our citizens.  This includes our obligation to the millions of immigrants living here today who followed the rules and respected our laws."

corp_example <- corpus(c(Clinton_1999 = txt_clinton, Bush_2005 = txt_bush, Obama_2012 = txt_obama, Trump_2019 = txt_trump))

example_covs <- covars_make_all(corp_example)


# TABLE 3 OUTPUT ---------
tab2 <- as.data.frame(sophistication:::get_covars_from_newdata.corpus(corp_example))
row.names(tab2) <- tab2[, "_docid"]
tab2 <- tab2[, c("google_min", "meanSentenceChars", "pr_noun", "meanWordChars")]
tab2 <- t(tab2)
tab2[1, , drop = FALSE]
round(tab2[2:4, ], 2)

#                   Clinton_1999 Bush_2005
# meanSentenceChars       155.50    153.50
# pr_noun                   0.30      0.23
# meanWordChars             4.94      4.72


# ---- lambdas computed with precision
load("data/my_BT_best.rda")
(prd <- predict_readability(BT_best, corp_example))
#                 lambda      prob   scaled
# Clinton_1999 -3.250914 0.2545336 36.38281
# Bush_2005    -3.528247 0.2055582 19.96412

# verify
coef(BT_best) %*% tab2

# relative probability
exp(prd["Clinton_1999", "lambda"]) / 
    (exp(prd["Clinton_1999", "lambda"]) + exp(prd["Bush_2005", "lambda"]))
exp(prd["Obama_2012", "lambda"]) / 
    (exp(prd["Obama_2012", "lambda"]) + exp(prd["Trump_2019", "lambda"]))

# ---- REPORTED LAMBDAS FROM TABLE 3
tab2rounded <- round(tab2, 2)
tab2rounded[1, 1] <- round(tab2[1, 1], 6)
tab2rounded[1, 2] <- round(tab2[1, 2], 10)
tab2lambdas <- round(round(coef(BT_best), 2) %*% tab2rounded, 2)
tab2lambdas
#      Clinton_1999 Bush_2005
# [1,]        -2.64     -2.93

# ---- Pr(Clinton snippet easier than Bush snippet) from TEXT
exp(tab2lambdas[1, "Clinton_1999"]) / 
    (exp(tab2lambdas[1, "Clinton_1999"]) + exp(tab2lambdas[1, "Bush_2005"]))
exp(tab2lambdas[1, "Obama_2012"]) / 
    (exp(tab2lambdas[1, "Obama_2012"]) + exp(tab2lambdas[1, "Trump_2019"]))
# Clinton_1999 
#    0.5719961 

## lambdas v. fifth-grade texts in text of 5.2
lamba5thgrade <- 
    predict_readability(BT_best, newdata = corpus_group(data_corpus_fifthgrade, groups = rep(1, ndoc(data_corpus_fifthgrade))))[, "lambda"]
lamba5thgrade
# redo with correct reference
predict_readability(BT_best, reference_top = lamba5thgrade,
                    newdata = corpus_group(data_corpus_fifthgrade, groups = rep(1, ndoc(data_corpus_fifthgrade))))
#      lambda prob scaled
# 1 -2.193864  0.5    100

# clinton and bush
predict_readability(BT_best, reference_top = lamba5thgrade, newdata = corp_example)
#                 lambda      prob   scaled
# Clinton_1999 -3.250914 0.2578736 36.76429
# Bush_2005    -3.528247 0.2084353 20.17345
```

## 09 SOTU paragraphs generate
```{r}
library("sophistication")
library("spacyr")

load("data/BT_best.RData")
spacy_initialize()
data(data_corpus_sotu, package = "quanteda.corpora")

# convert to paragraphs and tidy up

data_corpus_sotuparagraphs <- corpus_reshape(data_corpus_sotu, to = "paragraphs")
toremove <- rep(FALSE, ndoc(data_corpus_sotuparagraphs))

# remove paragraphs with all caps titles
# toremove <- toremove | 
#     grepl("^(([A-Z.\"\'&-]|[0-9])+\\.{0,1}\\s{1,})*([A-Z]+\\s{0,1})+[.:]{0,1}$", corpus_group(data_corpus_sotuparagraphs))
toremove <- toremove | 
    grepl("^([A-Z0-9[:punct:]]+\\s{0,1})+\\.{0,1}$", corpus_group(data_corpus_sotuparagraphs))

# remove paragraphs with long figures (from a table)
toremove <- toremove | 
     grepl("(\\d{1,3}(,\\d{3}){1,}(\\.\\d{2})*(\\s\\-\\s)+)", corpus_group(data_corpus_sotuparagraphs))
    
# remove any snippets with long ....
toremove <- toremove | 
    grepl("\\.{4,}", corpus_group(data_corpus_sotuparagraphs))

# remove any snippets with ----- (indicates a table)
toremove <- toremove |
    grepl("\\-{4,}", corpus_group(data_corpus_sotuparagraphs))

# remove e.g. "(a) For veterans."
toremove <- toremove |
    (grepl("^\\([a-zA-Z0-9]+\\)\\s+.*\\.$",  corpus_group(data_corpus_sotuparagraphs)) &
         ntoken(data_corpus_sotuparagraphs) <= 30)

data_corpus_sotuparagraphs <- corpus_subset(data_corpus_sotuparagraphs, !toremove)


# summary statistics
summary(summary(data_corpus_sotuparagraphs, n = ndoc(data_corpus_sotuparagraphs)))

# add readability stats
docvars(data_corpus_sotuparagraphs, "Flesch") <- 
    textstat_readability(data_corpus_sotuparagraphs, "Flesch")[["Flesch"]]

set.seed(42)

# add predicted BMS "static"
rdblty_2000 <- predict_readability(BT_best, data_corpus_sotuparagraphs,
                                   baseline_year = 2000, bootstrap_n = 100)
names(rdblty_2000) <- paste(names(rdblty_2000), "2000", sep = "_")
# add predicted BMS "dynamic"
rdblty_local <- predict_readability(BT_best, data_corpus_sotuparagraphs,
                                    baseline_year = lubridate::year(docvars(data_corpus_sotuparagraphs, "Date")),
                                    bootstrap_n = 100)
names(rdblty_local) <- paste(names(rdblty_local), "local", sep = "_")


docvars(data_corpus_sotuparagraphs) <- 
    cbind(docvars(data_corpus_sotuparagraphs), rdblty_2000, rdblty_local)

save(data_corpus_sotuparagraphs, file = "data/my_data_corpus_sotuparagraphs.rda")

```

## 10 Generate Figures 1-3
```{r}
library("sophistication")
library("ggplot2")
library("BradleyTerry2")
library("quanteda")

# create a subfolder for figures
dir.create("figures", showWarnings = FALSE)

## FIGURE 1 --------  

# get FRE scores for the snippets
load("data/my_job999866covars_chameleons.rda")
dat <- job999866covars_chameleons
FRE <- dat$predictors$Flesch
names(FRE) <- rownames(dat$predictors)

load("data/my_BT_best.rda")
# get lambdas from BMS best fitting model
main_lambdas <- BTabilities(BT_best)[,"ability"]

##
## HERE, WE SHOULD COMPUTE THE CONSTANTS USED FOR RESCALING
##

# rescale lambdas to the 0-100 space correctly
rescaled_lambdas <- 226.06927 + 57.93899 * main_lambdas
# check that they are matched up
m <- match(names(FRE), names(rescaled_lambdas)) ## they are matched up

ggplot(data.frame(FRE = FRE, rslambda = rescaled_lambdas), aes(x = FRE, y = rslambda)) +
    geom_point(size = .6) +
    labs(y = "Rescaled Best BT Model") +
    geom_smooth(method = "lm", se = TRUE) +
    geom_hline(yintercept = c(0, 100), linetype = "dashed", color = "firebrick") +
    theme(axis.text.x = element_text(size = 5),
          axis.text.y = element_text(size = 5)) +
    theme_classic()
dev.copy2pdf(file = "figures/figure1.pdf", height = 4.5, width = 7) 
# dev.copy2pdf(file = "../../manuscript_article/conditional_accept_submission/figs/figure1.pdf", 
#             height = 4.5, width = 7) 
dev.off()


## FIGURE 2 --------  
# can take 10-15 minutes to run since it has to tag all of the text
load("data/data_corpus_sotuparagraphs.rda")
library(quanteda.textstats)

data_corpus_sotuclean <- data_corpus_sotuparagraphs %>%
    corpus_reshape(to = "documents") %>%
    corpus_subset(!grepl("(1945|1956|1972|1978|1979|1980)b", docnames(.))) 
docvars(data_corpus_sotuclean, "year") <- lubridate::year(docvars(data_corpus_sotuclean, "Date"))
load("data/my_BT_best.rda")
set.seed(42)
lamba5thgrade <- 
    predict_readability(BT_best, newdata = corpus_group(data_corpus_fifthgrade, groups = rep(1, ndoc(data_corpus_fifthgrade))))[, "lambda"]
predrd <- predict_readability(BT_best, newdata = data_corpus_sotuclean, 
                              reference_top = lamba5thgrade,
                              baseline_year = docvars(data_corpus_sotuclean, "year"), 
                              bootstrap_n = 100)
# add the results to the corpus docvars
docvars(data_corpus_sotuclean, names(predrd)) <- predrd

# compute FRE ratio to 5th grade texts
docvars(data_corpus_sotuclean, "FREv5thgrade") <- 
    0.5 * 
    textstat_readability(data_corpus_sotuclean, "Flesch")[["Flesch"]] /
    textstat_readability(corpus_group(data_corpus_fifthgrade, 
                               groups = rep(1, ndoc(data_corpus_fifthgrade))), "Flesch")[["Flesch"]]

ggplot(data = docvars(data_corpus_sotuclean)) +
    xlab("") +
    ylab("Probability that SOTU is Easier than a 5th Grade Text") +
    geom_point(aes(x = year, y = prob), size = 1.5, color = "black", shape = 16) +
    geom_errorbar(aes(ymin = prob_lo, ymax = prob_hi, x = year), width = 0.25) +
    geom_smooth(aes(x = year, y = prob), span = .15, color = "blue") +
    geom_hline(yintercept = 0.50, linetype = "dashed", color = "firebrick") +
    theme(legend.position = c(1820, 0.4),
          axis.text.x = element_text(size = 5),
          axis.text.y = element_text(size = 5)) +
    theme_classic()
dev.copy2pdf(file = "figures/figure2.pdf", 
            height = 5, width = 8)
# dev.copy2pdf(file = "../../manuscript_article/conditional_accept_submission/figs/figure2.pdf",
#              height = 5, width = 8)
dev.off()


## FIGURE 3 --------  

load("data/data_corpus_sotuparagraphs.rda")
load("data/my_BT_best.rda")
data_corpus_sotucompare <- data_corpus_sotuparagraphs %>%
    corpus_reshape(to = "documents") %>%
    corpus_subset(lubridate::year(Date) %in% c(1956, 1945, 1972, 1974, 1978:1980))
predrd <- predict_readability(BT_best, newdata = data_corpus_sotucompare, 
                              baseline_year = lubridate::year(docvars(data_corpus_sotucompare, "Date")), 
                              bootstrap_n = 500)
pred <- data.frame(predrd, 
                   id = paste(docvars(data_corpus_sotucompare, "President"), 
                              lubridate::year(docvars(data_corpus_sotucompare, "Date")), sep = "-"), 
                   delivery = docvars(data_corpus_sotucompare, "delivery"),
                   stringsAsFactors = FALSE)
pred <- reshape(pred, timevar = "delivery", idvar = "id", direction = "wide")
pred <- within(pred, {
    PrSpokenEasier <- exp(lambda.spoken) / (exp(lambda.spoken) + exp(lambda.written))
    PrSpokenEasier_lo <- exp(lambda_lo.spoken) / (exp(lambda_lo.spoken) + exp(lambda_lo.written))
    PrSpokenEasier_hi <- exp(lambda_hi.spoken) / (exp(lambda_hi.spoken) + exp(lambda_hi.written))
})

# reorder factor levels for id
pred$id <- factor(pred$id, levels = rev(pred$id))

ggplot(pred, aes(x = id)) +
    geom_point(aes(y = PrSpokenEasier)) +
    scale_y_continuous(name = "Probability that Spoken SOTU was Easier than Written", 
                       limits = c(.3, .7),
                       breaks = seq(.3, .7, by = .1)) +
    labs(x = "") + 
    geom_hline(yintercept = .5, linetype = "dashed", color = "firebrick") +
    geom_errorbar(aes(ymin = PrSpokenEasier_lo, 
                      ymax = PrSpokenEasier_hi, x = id), width = 0) +
    theme(axis.text.x = element_text(size = 10),
          axis.text.y = element_text(size = 10)) +
    theme_classic() + 
    coord_flip()

dev.copy2pdf(file = "figures/figure3.pdf", 
             height = 3, width = 8)
# dev.copy2pdf(file = "../../manuscript_article/conditional_accept_submission/figs/figure3.pdf",
#              height = 3, width = 8)
dev.off()
```

## 11 Supplemental analysis
```{r}
# August 8, 2018

# Code to replicate the 'upper bound' on performance by our modeling approach.
# Full discussion of approach is as SUPPORTING INFORMATON C, 
# "Assessing Model Performance".  Ultimately this code produces a scalar value, 
# 0.79, which is treated as the 'true' denominator for the PCP of the various models.

# MOTIVATION:
# Note that the lower bound is percent correct predicted = .5
# But upper bound can be defined in various ways; ultimately it but needs to 
# reflect the fact that coders are gold standard, but that often DISAGREE.
#  No model, that's attempting to replicate what the coders do and is
# simultaneously producing a y in {0,1} prediction can cater to that 
# disagreement, so we need to divide performance  by a plausible (average) 
# UPPER BOUND.

rm(list=ls())

# function for fit (percent corr predicted)
prop.correct <- function(x, correction = 0.79) {
    sum(predict(x, type = "response") > .5) / length(predict(x, type = "response")) / correction
}

# create a subfolder for figures, if not already existing
dir.create("figures", showWarnings = FALSE)

## Appendix C -----------

# load the contest data
load("data/my_job999866covars_chameleons.rda")

# we need winner and loser columns
won_name <- as.character(job999866covars_chameleons$easier[,1])
lost_name <- as.character(job999866covars_chameleons$harder[,1])

# We need to know how many contests involved a given pair.
# That is, we need the denominator for our performance measure.
# For example, we could have contest A_B (A won, B lost)
# and a contest B_A (B won, A lost).  These contests are both 
# btwn A and B.  Clearly tho, upper bound on performance is 50%

# Now generate that denominator
# (1) put all the contests in one matrix
contests <- data.frame(won_name, lost_name)
# (2) sort 
contests.sort <- t(apply(contests, 1, sort))
# (3) combine the player names, and then get table of results
player.names <- paste(contests.sort[,1], contests.sort[,2], sep="_")
contest.counts <-table(player.names)
# (4) build a data frame with contest name (from player.names), 
# plus winner and loser
contest.results <- data.frame(contest=player.names, winner=NA, loser=NA)
contest.results$winner <- won_name
contest.results$loser <- lost_name
# (5) now, go through and for each contest, and calculate number of 
# times those snippets met, and max number of wins by one snippet
contest.name <- unique(player.names)

# This is a data frame just to take the results of that process
contest.outcomes <- data.frame(contest.title= contest.name,
                               number.battles = NA, max.wins=NA)

# This (inefficient) loop populates that data frame
cat("\n Calculating number of times snippets met and max wins by one of them\n ")
for (i in 1:length(contest.outcomes$contest.title)) {
    sub <- subset(contest.results, 
                  contest.results$contest==contest.outcomes$contest.title[i])
    contest.outcomes$number.battles[i] <- nrow(sub)
    contest.outcomes$max.wins[i] <- max(table(sub[,"winner"]))
}

#(6) now add column of 'best' we could possibly do with a model. That is, 
# max.wins divided by number of contests
contest.outcomes$machine.best <- contest.outcomes$max.wins/contest.outcomes$number.battles

# Ultimately this will be a vector of values, which reflects the distribution of 
# best possible performance.
# Now we obtain the mean 'best' performance, which is what will use as our upper bound
cat("\nUpper bound on performance for this data is: \n")
print(round(mean(contest.outcomes$machine.best), d=2))
#so, mean performance is 0.79.  That's the upper bound.

#(6b) In principle, we *could* reweight this by the number of contests involved 
# -- that is, multiply the  machine best for that contest type by 3 if it 
# involves three contests etc.  Then take mean. This makes no difference 
# in practice.

# weighted <- rep(contest.outcomes$machine.best, times = contest.outcomes$number.battles)
# mean(weighted)
# yields mean of ~.79 again.

# Table 1 -----------

load("data/Best_Model_Results_list.RData")
# output models in terms of PCP
table1 <- paste("\nTABLE 1 Supplemental\n -------------------------------------------\n",
                sprintf("%-20s ", "Model"), "   PCP orig   PCP Adj\n",
                "========================  =======   =======\n") 
for (m in seq_along(model_results)) {
    table1 <- paste(table1, 
                    sprintf("%-25s", names(model_results)[m]),
                    sprintf(" %2.3f", prop.correct(model_results[[m]], correction = 1)), 
                    sprintf("    %2.3f", prop.correct(model_results[[m]], correction = 0.79)), 
                    "\n")
}
table1 <- paste0(table1, " -------------------------------------------\n\n")
cat(table1)
# Model                    PCP orig   PCP Adj
# BT_basic_Flesch            0.568     0.719 
# BT_basic_RF                0.582     0.737 
# BT_optimal_Flesch          0.583     0.738 
# BT_best                    0.585     0.741 



## Appendix D: TABLE 2 ---------

load("data/my_job999866covars_chameleons.rda")
library("BradleyTerry2")

# baseline Flesch model
BT_basic_Flesch <- BTm(player1 = easier, player2 = harder, formula = ~ Flesch[ID], id = "ID", data = job999866covars_chameleons)

# Dale-Chall
BT_DC <- BTm(player1 = easier, player2 = harder, formula = ~ Dale.Chall.old[ID], id = "ID", data = job999866covars_chameleons)

# FOG 
BT_FOG <- BTm(player1 = easier, player2 = harder, formula = ~ FOG[ID], id = "ID", data = job999866covars_chameleons)

# SMOG 
BT_SMOG <- BTm(player1 = easier, player2 = harder, formula = ~SMOG[ID], id = "ID", data = job999866covars_chameleons)

# Spache
BT_Spache <- BTm(player1 = easier, player2 = harder, formula = ~ Spache[ID], id = "ID", data = job999866covars_chameleons)

# Coleman-Liau
BT_CL <- BTm(player1 = easier, player2 = harder, formula = ~ Coleman.Liau.ECP[ID], id = "ID", data = job999866covars_chameleons)


model_results_classic <- list(FRE = BT_basic_Flesch, 
                              "Dale-Chall" = BT_DC, 
                              FOG = BT_FOG,
                              SMOG = BT_SMOG,
                              Spache = BT_Spache,
                              "Coleman-Liau" = BT_CL)

save(model_results_classic, file = "data/Classic_Model_Results_list.rda")

# output models in terms of PCP
table2 <- paste("\nTABLE 2\n ------------------------------------------\n",
                sprintf("%-20s ", "Model"), "        AIC     PCP\n",
                "========================  =========  =====\n") 
for (m in seq_along(model_results_classic)) {
    table2 <- paste(table2, 
                    sprintf("%-25s", names(model_results_classic)[m]),
                    sprintf(" %5.2f", model_results_classic[[m]][["aic"]]),
                    sprintf(" %2.3f", prop.correct(model_results_classic[[m]])), 
                    "\n")
}
table2 <- paste0(table2, " ------------------------------------------\n\n")
cat(table2)

# TABLE 2
# Model                         AIC     PCP
# FRE                        26267.79  0.719 
# Dale-Chall                 26277.86  0.722 
# FOG                        26081.44  0.726 
# SMOG                       26188.21  0.666 
# Spache                     25906.35  0.742 
# Coleman-Liau               26571.63  0.697 


## FIGURE 1: SUPPLEMENTAL - Variable Importance Plots  --------  

library("randomForest")
load("data/my_rf_model_non_bias_reduced.rda")
load("data/my_rf_model_bias_reduced.rda")
par(mfrow=c(2,1))
varImpPlot(mod_bias_reduced, main = "Bias Reduced", pch = 16)
varImpPlot(mod_non_bias_reduced, main = "Not Bias Reduced", pch = 16)
dev.copy2pdf(file = "figures/figureS1.pdf", 
             width = 11, height = 9)
# dev.copy2pdf(file = "../../manuscript_article/conditional_accept_submission/figs/figureS1.pdf",
#              width = 11, height = 9)
dev.off()


## FIGURE 2: SUPPLEMENTAL --------  

load("data/data_corpus_sotuparagraphs.rda")
library("ggplot2")
library("quanteda")
ggplot(docvars(data_corpus_sotuparagraphs)) + 
    geom_smooth(aes(x = Date, y = log(prob_local / prob_2000))) + 
    geom_hline(yintercept = 0, linetype = "dashed", color = "firebrick") +
    labs(x = "", y = "log ratio of easiness from time-specific versus 2000-only") + 
    theme_classic() + 
    theme(axis.text.x = element_text(size = 15),
          axis.text.y = element_text(size = 15)) +
    annotate("text", x = as.Date("1840-01-01"), y = c(.015, .014, .013),
             label = c("Earlier texts are considered", 
                       "easier when using locally",
                       "fit word rarity baselines"))
dev.copy2pdf(file = "figures/figureS2.pdf", 
             height = 5, width = 8)
# dev.copy2pdf(file = "../../manuscript_article/conditional_accept_submission/figs/figureS2.pdf",
#              height = 5, width = 8)
dev.off()
```
